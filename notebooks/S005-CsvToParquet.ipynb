{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7486e1f-d6b2-4f2d-8762-653e7bdce75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget  -P $FLINK_HOME/lib https://repo1.maven.org/maven2/org/apache/flink/flink-parquet/1.15.3/flink-parquet-1.15.3.jar\n",
    "\n",
    "# wget  -P $FLINK_HOME/lib https://repo1.maven.org/maven2/org/apache/flink/flink-sql-parquet/1.15.3/flink-sql-parquet-1.15.3.jar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3b5aee-3246-4179-abba-887d4d36db13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/flink-1.15.3/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.7/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pyflink.table import EnvironmentSettings, TableEnvironment, DataTypes, CsvTableSource\n",
    "\n",
    "from pyflink.table.expressions import col\n",
    "from pyflink.table.window import Over, GroupWindow\n",
    "from pyflink.table.expressions import col, UNBOUNDED_RANGE, CURRENT_RANGE\n",
    "from pyflink.table.udf import udf\n",
    "# create a batch TableEnvironment\n",
    "env_settings = EnvironmentSettings.in_batch_mode()\n",
    "table_env = TableEnvironment.create(env_settings)\n",
    "\n",
    "# this python/pyflink refers to python packages inside flink-dev, not refering to /opt/flink1-15.3/lib but we copied parquest jar there\n",
    "\n",
    "# table_env.get_config().get_configuration().set_string(\"pipeline.jars\", \"file:///opt/flink-1.15.3/lib/flink-shaded-hadoop-3-uber-3.1.1.7.2.8.0-224-9.0.jar;file:///opt/flink-1.15.3/lib/flink-parquet-1.15.3.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2952307-f1a4-4ee2-b912-a128ac5ad1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registered Tables List\n",
      "['invoices']\n",
      "\n",
      "Financial Trxs Schema\n",
      "(\n",
      "  `InvoiceNo` STRING,\n",
      "  `StockCode` STRING,\n",
      "  `Description` STRING,\n",
      "  `Quantity` DOUBLE,\n",
      "  `InvoiceDate` TIMESTAMP(3),\n",
      "  `UnitPrice` DOUBLE,\n",
      "  `CustomerID` STRING,\n",
      "  `Country` STRING,\n",
      "  WATERMARK FOR `InvoiceDate`: TIMESTAMP(3) AS `InvoiceDate` - INTERVAL '1' SECOND\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country\n",
    "# 536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/01/2010 8:26,2.55,17850,United Kingdom\n",
    "\n",
    "source_ddl = \"\"\"\n",
    "            CREATE TABLE invoices (\n",
    "                   InvoiceNo STRING,\n",
    "                   StockCode  STRING,\n",
    "                   Description  STRING,\n",
    "                   Quantity DOUBLE,\n",
    "                   InvoiceDate TIMESTAMP(3),\n",
    "                   UnitPrice DOUBLE,\n",
    "                   CustomerID STRING,\n",
    "                   Country STRING,\n",
    "                   WATERMARK FOR InvoiceDate AS InvoiceDate - INTERVAL '1' SECOND\n",
    "\n",
    "                    ) WITH (\n",
    "                      'connector' = 'filesystem',          \n",
    "                     'path' = 'file:////home/training/flink-dev/data/ecommerce-clean.csv', \n",
    "                      'format' = 'csv'\n",
    "                    )\"\"\"\n",
    "\n",
    "\n",
    "table_env.execute_sql(source_ddl) \n",
    "\n",
    "invoices = table_env.from_path(\"invoices\")\n",
    "##############################\n",
    "print('\\nRegistered Tables List')\n",
    "print(table_env.list_tables())\n",
    "\n",
    "print('\\nFinancial Trxs Schema')\n",
    "invoices.print_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c66164d-d4af-468a-a361-7ffa610e1059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f48d8414490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sink to write parquet files\n",
    "# file:///home/rps/workshop/data/ecommerce-clean.parquet is a folder, will contain many partitions files\n",
    "sink_ddl_parquet=f\"\"\"\n",
    "    create table `EComParquetResult`(\n",
    "                 InvoiceNo STRING,\n",
    "                   StockCode  STRING,\n",
    "                   Description  STRING,\n",
    "                   Quantity DOUBLE,\n",
    "                   InvoiceDate TIMESTAMP(3),\n",
    "                   UnitPrice DOUBLE,\n",
    "                   CustomerID STRING,\n",
    "                   Country STRING\n",
    "    ) with (\n",
    "        'connector' = 'filesystem',\n",
    "        'format' = 'parquet',\n",
    "        'path' = 'file:////home/training/flink-dev/data/ecommerce-clean.parquet'\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "table_env.execute_sql(sink_ddl_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22784f7e-b34b-4955-bd33-2b7684f0e80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.flink.api.java.ClosureCleaner (file:/opt/flink-1.15.3/lib/flink-dist-1.15.3.jar) to field java.util.LinkedHashMap.serialVersionUID\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.flink.api.java.ClosureCleaner\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 16:51:52,145 INFO  org.apache.hadoop.io.compress.CodecPool                      [] - Got brand-new compressor [.snappy]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyflink.table.table_result.TableResult at 0x7f4858391400>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emit the data from source to target\n",
    "\n",
    "table_env.execute_sql(\"INSERT INTO EComParquetResult select * from invoices\").wait()\n",
    "\n",
    "invoices.execute_insert(\"EComParquetResult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404017af-5cc4-4c34-9cd3-d65c3d1fa2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
